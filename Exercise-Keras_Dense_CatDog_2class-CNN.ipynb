{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wir implementieren einen Hund-Katze Klassifikator mit CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folgende Funktion nimmt ein Bild entgegen und skaliert das Bild auf 32x32 RGB-Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "\n",
    "    return cv2.resize(image, size)\n",
    "#cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden Sie die Daten aus der Ãœbung zu Neuronalen Netzen (Hund-Katze-Klassifikator):\n",
    "\n",
    "Schreiben Sie eine Funktion, die die Bilder einliest, mit Hilfe der Funktion image_to_feature_vector vorverarbeiten. Anschliessend sollen die Vektoren in eine data-Matrix geschrieben werden, \n",
    "und ein label-Vektor ist zu erzeugen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "23000\n",
      "22000\n",
      "21000\n",
      "20000\n",
      "19000\n",
      "18000\n",
      "17000\n",
      "16000\n",
      "15000\n",
      "14000\n",
      "13000\n",
      "12000\n",
      "11000\n",
      "10000\n",
      "9000\n",
      "8000\n",
      "7000\n",
      "6000\n",
      "5000\n",
      "4000\n",
      "3000\n",
      "2000\n",
      "1000\n",
      "0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def getTestData(path):\n",
    "    data = os.listdir(path)\n",
    "    Xtrain = np.zeros((len(data),32,32,3)) # changed here to fit 32*32 RGB Pixels instead of 3072\n",
    "    ytrain = np.zeros((len(data)))\n",
    "    i=0\n",
    "    for j in range(len(data)):\n",
    "        imgName=data[j]\n",
    "        i=i+1\n",
    "        if((len(data)-i)%1000 ==0):\n",
    "            print(len(data)-i)\n",
    "        img = cv2.imread(os.path.join(path,imgName))\n",
    "        Xtrain[j]=image_to_feature_vector(img)\n",
    "        if(\"cat\" in imgName):\n",
    "            ytrain[j]=0 #0=Cat\n",
    "        else:\n",
    "            ytrain[j]=1 #1=Dog\n",
    "    print(\"Done\")\n",
    "    return Xtrain, ytrain\n",
    "\n",
    "Xtrain, ytrain = getTestData(\"C:\\\\Users\\\\ABleicher\\\\Desktop\\\\train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitten Sie die Daten in ein train/test-set.\n",
    "\n",
    "Macht es Sinn die Daten zu normieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtr=Xtrain #save\n",
    "print(Xtrain.shape)\n",
    "Xtrain /= 255\n",
    "print(Xtrain.shape)\n",
    "\n",
    "(Xtr, Xte, ytr, yte) = train_test_split(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen Sie ein CNN mit Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(32,32,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... und starten Sie das Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750,)\n",
      "Epoch 1/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4638 - accuracy: 0.7678\n",
      "Epoch 2/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.4510 - accuracy: 0.7687\n",
      "Epoch 3/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4384 - accuracy: 0.7792\n",
      "Epoch 4/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4271 - accuracy: 0.7846\n",
      "Epoch 5/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4152 - accuracy: 0.7890\n",
      "Epoch 6/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4001 - accuracy: 0.7959\n",
      "Epoch 7/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3957 - accuracy: 0.7977\n",
      "Epoch 8/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3824 - accuracy: 0.8067\n",
      "Epoch 9/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3678 - accuracy: 0.8133\n",
      "Epoch 10/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3560 - accuracy: 0.8197\n",
      "Epoch 11/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3474 - accuracy: 0.8280\n",
      "Epoch 12/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3358 - accuracy: 0.8227\n",
      "Epoch 13/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3352 - accuracy: 0.8260\n",
      "Epoch 14/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.3200 - accuracy: 0.8347\n",
      "Epoch 15/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3196 - accuracy: 0.8364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e859578e20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ytr.shape)\n",
    "model.fit(Xtr, ytr, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluieren Sie das Netz auf den held-back Test-Daten\n",
    "\n",
    "\n",
    "Berechnen Sie die Akkuratheit und die Verwechselungsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 1s 5ms/step\n",
      "[[2284  831]\n",
      " [ 664 2471]]\n",
      "0.7608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predictTest = model.predict(Xte)\n",
    "yPred = np.empty([0])\n",
    "for y in predictTest:\n",
    "    yPred= np.append(yPred,np.round(y))\n",
    "print(confusion_matrix(yte, yPred))\n",
    "print(accuracy_score(yte, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spielwiese\n",
    "\n",
    "Vergleichen Sie: \n",
    "\n",
    "- unterschiedliche Netztopologien\n",
    "- unterschiedliche Trainingsverfahren\n",
    "- Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndTestModel(modelDeclared):\n",
    "    modelDeclared.fit(Xtr, ytr, epochs=15)\n",
    "    predictTest = model.predict(Xte)\n",
    "    yPred = np.empty([0])\n",
    "    for y in predictTest:\n",
    "        yPred= np.append(yPred,np.round(y))\n",
    "    print(confusion_matrix(yte, yPred))\n",
    "    print(accuracy_score(yte, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "586/586 [==============================] - 15s 24ms/step - loss: 0.6884 - accuracy: 0.5329\n",
      "Epoch 2/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.6579 - accuracy: 0.6148\n",
      "Epoch 3/15\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 0.6038 - accuracy: 0.6829\n",
      "Epoch 4/15\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 0.5390 - accuracy: 0.7383\n",
      "Epoch 5/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.4917 - accuracy: 0.7681\n",
      "Epoch 6/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.4625 - accuracy: 0.7871\n",
      "Epoch 7/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.4323 - accuracy: 0.8058\n",
      "Epoch 8/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.4118 - accuracy: 0.8177\n",
      "Epoch 9/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.3858 - accuracy: 0.8305\n",
      "Epoch 10/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3632 - accuracy: 0.8394\n",
      "Epoch 11/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3489 - accuracy: 0.8496\n",
      "Epoch 12/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3244 - accuracy: 0.8587\n",
      "Epoch 13/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.3104 - accuracy: 0.8707\n",
      "Epoch 14/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.2877 - accuracy: 0.8815\n",
      "Epoch 15/15\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 0.2775 - accuracy: 0.8835\n",
      "196/196 [==============================] - 1s 6ms/step\n",
      "[[2669  446]\n",
      " [ 874 2261]]\n",
      "0.7888\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(32,32,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "fitAndTestModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 0.6910 - accuracy: 0.5268\n",
      "Epoch 2/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.6793 - accuracy: 0.5723\n",
      "Epoch 3/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.6634 - accuracy: 0.6095\n",
      "Epoch 4/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.6390 - accuracy: 0.6419\n",
      "Epoch 5/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.6013 - accuracy: 0.6836\n",
      "Epoch 6/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.5656 - accuracy: 0.7120\n",
      "Epoch 7/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.5402 - accuracy: 0.7356\n",
      "Epoch 8/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.5134 - accuracy: 0.7558\n",
      "Epoch 9/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.4940 - accuracy: 0.7696\n",
      "Epoch 10/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.4728 - accuracy: 0.7809\n",
      "Epoch 11/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.4530 - accuracy: 0.7948\n",
      "Epoch 12/15\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 0.4337 - accuracy: 0.8113\n",
      "Epoch 13/15\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.4177 - accuracy: 0.8156\n",
      "Epoch 14/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.4002 - accuracy: 0.8233\n",
      "Epoch 15/15\n",
      "586/586 [==============================] - 15s 26ms/step - loss: 0.3925 - accuracy: 0.8299\n",
      "196/196 [==============================] - 1s 6ms/step\n",
      "[[1963 1152]\n",
      " [ 270 2865]]\n",
      "0.77248\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(32,32,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "opt=SGD(lr=0.01, momentum=0.8)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fitAndTestModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer-Learning\n",
    "\n",
    "In der Vorlesung wurde *Transfer-Learning* als effizientes Verfahren zum anpassen bereits vortrainierter neuronaler Netze beschrieben. Wenden die das Verfahren auch auf ihr Problem an. Verwenden sie dabei beispielsweise ein ResNet50 aus [Keras Applications](https://keras.io/api/applications/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications.resnet50 as resnet50\n",
    "def preprocess(image):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = resnet50.preprocess_input(resized_image)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSet resized\n",
      "testSet resized\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from functools import partial\n",
    "\n",
    "train_set=np.zeros((round((len(Xtr)/2)), 224,224,3))\n",
    "for i in range(round(len(Xtr)/2)):\n",
    "    train_set[i]=preprocess(Xtr[i])\n",
    "print(\"trainSet resized\")\n",
    "test_set=np.zeros((len(Xte), 224,224,3))\n",
    "for i in range(len(Xte)):\n",
    "    test_set[i]=preprocess(Xte[i])\n",
    "print(\"testSet resized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "586/586 [==============================] - 39s 56ms/step - loss: 0.6846 - accuracy: 0.4973\n",
      "Epoch 2/5\n",
      "586/586 [==============================] - 35s 60ms/step - loss: 0.6634 - accuracy: 0.4973\n",
      "Epoch 3/5\n",
      "586/586 [==============================] - 35s 60ms/step - loss: 0.6543 - accuracy: 0.4973\n",
      "Epoch 4/5\n",
      "586/586 [==============================] - 36s 61ms/step - loss: 0.6491 - accuracy: 0.4973\n",
      "Epoch 5/5\n",
      "586/586 [==============================] - 34s 59ms/step - loss: 0.6449 - accuracy: 0.4973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0f164fdf0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "base_model=ResNet50(weights='imagenet', include_top=False)\n",
    "avg=GlobalAveragePooling2D()(base_model.output)\n",
    "output=Dense(1, activation=\"softmax\")(avg)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(Xtr, ytr, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich mit Feed-forward Netz\n",
    "\n",
    "Vergleichen Sie ihre CNN-Ergebnisse mit den Ergebnisse aus dem Feed-fwd Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
